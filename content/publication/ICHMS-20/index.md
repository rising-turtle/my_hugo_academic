---
title: "Human-Robot Interaction for Assisted Object Grasping by a Wearable Robotic Object Manipulation Aid for the Blind"
authors:
- Lingqiu Jin
- He Zhang
- Cang Ye
date: "2020-02-20T00:00:00Z"
doi: ""

# Schedule page publish date (NOT publication's date).
publishDate: "2017-01-01T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["1"]

# Publication name and optional abbreviated publication name.
publication: In *Proceedings of 1st IEEE International Conference on Human-Machine Systems (ICHMS)*, Rome, Sep. 7-9
publication_short: In *Proceedings of 1st IEEE International Conference on Human-Machine Systems (ICHMS)*, Rome, Sep. 7-9

abstract: This paper presents a new hand-worn device, called wearable robotic object manipulation aid (W-ROMA), that can help a visually impaired individual locate a target object and guide the hand to take a hold of it. The device consists of a sensing unit and a guiding unit. The sensing unit uses a Structure Core sensor, comprising of an RGB-D camera and an Inertial Measurement Unit (IMU), to detect the target object and estimate the device pose. Based on the object and pose information, the guiding unit computes the Desired Hand Movement (DHM) and convey it to the user by an electro-tactile display to guide the hand to approach the object. A speech interface is developed and used as an additional way to convey the DHM and used for human-robot interaction. A new method, called Depth Enhanced Visual-Inertial Odometry (DVIO), is proposed for 6-DOF device pose estimation. It tightly couples the cameraâ€™s depth and visual data with the IMU data in a graph optimization process to produce more accurate pose estimation than the existing state-of-the-art approach. Experimental results demonstrate that the DVIO method outperforms the state-of-the-art VIO approach in 6-DOF pose estimation.

# Summary. An optional shortened abstract.
summary:

# tags:
# - Source Themes
featured: true

# links:
#- name: Custom Link
#  url: http://example.org
url_pdf: '' #http://eprints.soton.ac.uk/352095/1/Cushen-IMV2013.pdf
# url_code: '#'
# url_dataset: '#'
# url_poster: '#'
# url_project: ''
# url_slides: ''
# url_source: '#'
# url_video: '#'

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  # caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)'
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
- internal-project

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: example
---
