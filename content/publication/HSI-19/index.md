---
title: "Human-Robot Interaction for Assisted Wayfinding of a Robotic Navigation Aid for the Blind"
authors:
- He Zhang
- Cang Ye
date: "2019-06-20T00:00:00Z"
doi: "10.1109/HSI47298.2019.8942612"

# Schedule page publish date (NOT publication's date).
publishDate: "2017-01-01T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["1"]

# Publication name and optional abbreviated publication name.
publication: In *Proceedings of 12th International Conference on Human System Interaction (HSI)*, Richmond, June 25-27 (***Best Paper Award***)
publication_short: In *Proceedings of 12th International Conference on Human System Interaction (HSI)*, Richmond, June 25-27 (***Best Paper Award***)

abstract: This paper introduces a new robotic navigation aid (RNA) for the visually impaired (VI). Two fundamental functions wayfinding and human-robot interaction (HRI) are presented for assisted wayfinding. The problem of wayfinding involves planning a path from the RNA’s current location to the destination and following the path to get to the destination. To address the problem, we developed a new visual inertial odometry to estimate the RNA’s pose by using the image and depth data from an RGB-D camera and the inertial data of an IMU. The estimated pose is used for path planning. To guide the user to follow the planned path, we designed an HRI interface with two guiding modes the robocane mode and white-came mode. In the robocane mode, the RNA uses a motorized rolling tip to steer itself into the desired direction of travel (DDT) for the user to follow and track the planned path. In the white-cane mode, the RNA uses its speech interface to indicate the DDT to the user by audio messages. In this mode, the user swings the RNA just like using a conventional white cane. To make mode selection effortless, we developed a human intent detection (HID) method based on the decision tree mode. The method can detect the user intent and automatically select the appropriate mode according to the detected intent. Experimental results demonstrate the efficacies of the VIO, HRI, and HID methods for assisted wayfinding.

# Summary. An optional shortened abstract.
summary:

# tags:
# - Source Themes
featured: true

# links:
#- name: Custom Link
#  url: http://example.org
url_pdf: 'https://www.researchgate.net/profile/He_Zhang72/publication/338370643_Human-Robot_Interaction_for_Assisted_Wayfinding_of_a_Robotic_Navigation_Aid_for_the_Blind/links/5e13d142a6fdcc28375db16b/Human-Robot-Interaction-for-Assisted-Wayfinding-of-a-Robotic-Navigation-Aid-for-the-Blind.pdf' #http://eprints.soton.ac.uk/352095/1/Cushen-IMV2013.pdf
# url_code: '#'
# url_dataset: '#'
# url_poster: '#'
# url_project: ''
# url_slides: ''
# url_source: '#'
# url_video: '#'

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  # caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)'
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
- internal-project

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: example
---
